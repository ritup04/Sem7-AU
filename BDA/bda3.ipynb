{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e617203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Least Frequent Words:\n",
      "barked: 1\n",
      "chased: 1\n",
      "hadoop_0: 1000\n",
      "hadoop_1: 1000\n",
      "hadoop_2: 1000\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "# Step 1 – Mapper Function\n",
    "def mapper(file_path, stopwords):\n",
    "    mapped = []\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            for word in words:\n",
    "                w = word.lower().strip(\",.?!:;\\\"'()[]{}\")  # clean punctuation\n",
    "                if w and w not in stopwords and len(w) > 5:  # ignore stopwords + only >5 chars\n",
    "                    mapped.append((w, 1))\n",
    "    return mapped\n",
    "\n",
    "# Step 2 – Reducer Function\n",
    "def reducer(mapped_data):\n",
    "    reduced = defaultdict(int)\n",
    "    for word, count in mapped_data:\n",
    "        reduced[word] += count\n",
    "    return reduced\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define stopwords\n",
    "    stopwords = {\"the\", \"and\", \"of\", \"to\", \"a\", \"in\", \"is\", \"it\", \"that\", \"for\", \"on\", \"with\", \"as\", \"by\", \"at\"}\n",
    "\n",
    "    # Step 3 – Process multiple text files\n",
    "    all_files = glob.glob(\"*.txt\")  # pick all .txt files in current dir\n",
    "    mapped_data = []\n",
    "    for file_path in all_files:\n",
    "        mapped_data.extend(mapper(file_path, stopwords))\n",
    "\n",
    "    # Step 4 – Reduce phase\n",
    "    reduced_data = reducer(mapped_data)\n",
    "\n",
    "    # Sort words by frequency\n",
    "    sorted_words = sorted(reduced_data.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "    least_frequent = sorted(reduced_data.items(), key=lambda x: x[1])[:5]\n",
    "    print(\"\\nTop 5 Least Frequent Words:\")\n",
    "    for word, freq in least_frequent:\n",
    "        print(f\"{word}: {freq}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
